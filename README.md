# MPEG-G Microbiome Classification Solutions

[![Python](https://img.shields.io/badge/python-3.10.6-blue.svg)](https://www.python.org/downloads/release/python-3106/)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://www.docker.com/)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.7.6-green.svg)](https://xgboost.readthedocs.io/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0.1-red.svg)](https://pytorch.org/)
[![Carbon Tracking](https://img.shields.io/badge/carbon-tracked-green.svg)](https://codecarbon.io/)

Two comprehensive machine learning approaches for microbiome classification using MPEG-G compressed genomic data, achieving **12th place** on the private leaderboard with both centralized and federated learning solutions.

## ğŸ† Competition Results
- **Centralized Solution**: Log Loss 0.0322 Â± 0.0206 (12th private leaderboard: 0.0266)
- **Federated Solution**: Log Loss 0.0296 (achieved with deterministic training)

## ğŸ“‹ Table of Contents

- [Competition Results](#-competition-results)
- [Overview and Objective](#-overview-and-objective)
- [Project Structure](#-project-structure)
- [Prerequisites](#-prerequisites)
- [Installation](#-installation)
- [Architecture](#architecture-diagram)
- [Data Pipeline](#etl-process)
- [Model Training](#data-modeling)
- [Results & Visualizations](#-results--visualizations)
- [Carbon Footprint](#-carbon-footprint)
- [Usage](#-usage)
- [File Structure](#-file-structure)
- [Contributing](#-contributing)

## ğŸ”¬ Overview and Objective

This solution was developed for the **[MPEG-G Microbiome Classification challenge](https://zindi.africa/competitions/mpeg-g-microbiome-classification-challenge)** hosted on Zindi. The central question was to predict the source of the 16S RNA microbiome analysis samples from one of the 4 different body sites (mouth, nasal, skin, gut) based only on the genomic sequences using two machine learning approaches. The FASTQ files were coded using MPEG-G format. TrainFiles.zip and TestFiles.zip contain the coded files in MGB format along with Train.csv (SampleType) and Test.csv are the main data files supplied.

**ğŸ”— Competition Details:**
- **Platform**: [Zindi Africa](https://zindi.africa/competitions/mpeg-g-microbiome-classification-challenge)
- **Challenge Type**: Microbiome Classification
- **Data Format**: MPEG-G compressed genomic sequences (.mgb files)
- **Objective**: Multi-class classification (4 body sites)
- **Evaluation Metric**: Logarithmic Loss
- **Final Ranking**: 8th place on private leaderboard

## ğŸ¯ Project Structure

This repository contains two complementary approaches:

### ğŸ¯ **Centralized Solution** (`microbiome_solution_notebook.ipynb`)
A comprehensive end-to-end pipeline that processes raw MGB files locally using Docker containers, extracts k-mer features, and trains an XGBoost classifier.

### ğŸŒ **Federated Solution** (`federated_microbiome_fixed.ipynb`)
A privacy-preserving federated learning approach using neural networks with FedAvg aggregation, designed to run on Kaggle with pre-processed k-mer data.

## ğŸ³ Prerequisites

### System Requirements

#### For Centralized Solution (Local Execution)
- **Operating System**: Windows 10/11 with WSL2 or Linux
- **Memory**: Minimum 8GB RAM (16GB recommended)
- **Storage**: ~5GB free space for Docker images and data
- **Docker**: Docker Desktop for Windows or Docker Engine for Linux

#### For Federated Solution (Kaggle Execution)
- **Platform**: Kaggle Kernels with GPU enabled
- **Pre-processed Data**: K-mer count matrices (available in Kaggle dataset)

### Required Docker Images (Centralized Only)

```bash
# Genie: MPEG-G decompression (MGB â†’ FASTQ)
docker pull muefab/genie:latest

# Jellyfish: K-mer counting
docker pull quay.io/biocontainers/kmer-jellyfish:2.3.1--py310h184ae93_5
```

## ğŸ“¦ Installation

### Quick Start
1. Clone this repository
2. Install Python dependencies: `pip install -r requirements.txt`
3. For centralized solution: Set up Docker as described below
4. For federated solution: Upload notebooks to Kaggle

### Detailed Setup

#### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/microbiome-classification
cd microbiome-classification
```

#### 2. Python Environment
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Docker Setup (Centralized Solution Only)
```bash
# Pull required Docker images
docker pull muefab/genie:latest
docker pull quay.io/biocontainers/kmer-jellyfish:2.3.1--py310h184ae93_5

# Verify installation
docker run --rm muefab/genie:latest help
```

#### 4. Data Preparation
```
Project Root/
â”œâ”€â”€ TrainFiles.zip      # Training MGB files
â”œâ”€â”€ TestFiles.zip       # Test MGB files
â”œâ”€â”€ Train.csv          # Training labels
```

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA PIPELINE ARCHITECTURE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CENTRALIZED SOLUTION (Local Execution)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ZIP Files   â”‚â”€â”€â”€â–¶â”‚ MGB Files   â”‚â”€â”€â”€â–¶â”‚ Docker      â”‚â”€â”€â”€â–¶â”‚ K-mer       â”‚
â”‚ Extraction  â”‚    â”‚ Extraction  â”‚    â”‚ Processing  â”‚    â”‚ Matrices    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Predictions â”‚â—€â”€â”€â”€â”‚ XGBoost     â”‚â—€â”€â”€â”€â”‚ Feature     â”‚â—€â”€â”€â”€â”‚ CLR         â”‚
â”‚ & Submissionâ”‚    â”‚ Training    â”‚    â”‚ Selection   â”‚    â”‚ Transform   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FEDERATED SOLUTION (Kaggle Execution)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pre-processedâ”‚â”€â”€â”€â–¶â”‚ CLR + Scale â”‚â”€â”€â”€â–¶â”‚ Feature     â”‚â”€â”€â”€â–¶â”‚ Client      â”‚
â”‚ K-mer Data   â”‚    â”‚ Transform   â”‚    â”‚ Selection   â”‚    â”‚ Split       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â”‚
                                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final       â”‚â—€â”€â”€â”€â”‚ FedAvg      â”‚â—€â”€â”€â”€â”‚ Neural Net  â”‚â—€â”€â”€â”€â”‚ 4 Federated â”‚
â”‚ Predictions â”‚    â”‚ Aggregation â”‚    â”‚ Training    â”‚    â”‚ Clients     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ETL Process

### Extract
**Common for Both Solutions:**
- **Input**: ZIP files containing MGB (MPEG-G Binary) files
- **Centralized**: Direct ZIP extraction and MGB processing via Docker. Two Docker containers are used the two processes:
  - **Genie**: MGB â†’ FASTQ conversion (`muefab/genie:latest`)
  - **Jellyfish**: 8-mer counting and extracting (`quay.io/biocontainers/kmer-jellyfish:2.3.1--py310h184ae93_5`)

**Streaming Strategy**: It was essential to avoid extracting all FASTQ files directly on the machine. The solution uses streaming of decoding results from Genie in temporary files, then passes them to the Docker image of Jellyfish (a bioinformatics tool for k-mer counting). The temporary files are deleted after k-mer extraction. The resulting `train_kmercount.csv` and `test_kmercount.csv` are then used for downstream machine learning analysis.

- **Federated**: The k-mer count CSV files were uploaded to Kaggle (`/kaggle/input/microbiome-challengezindi-kmercount`) to be used directly for the federated solution

### Transform

#### **Centralized Solution Transform Pipeline:**
```python
MGB Files â†’ Docker Genie â†’ FASTQ â†’ Docker Jellyfish â†’ K-mer Counts
                                                           â†“
CLR Transformation â†’ Feature Selection (2000 features) â†’ XGBoost Ready
```


#### **Federated Solution Transform Pipeline:**
```python
8-mer Counts â†’ CLR Transformation â†’ Scaling â†’ Feature Selection â†’ Client Split
                                                                         â†“
                                            4 Federated Clients (Body Sites)
```

### Load
- **Centralized**: Direct training on full `train_kmercount.csv` 
- **Federated**: Data distributed across 4 clients (Mouth, Nasal, Skin, Stool)

---

## Data Modeling

### Models Used

#### **Centralized Solution: XGBoost**
```python
XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1
)
```

#### **Federated Solution: Neural Networks**

**Architecture: 4-Layer Multi-Layer Perceptron (SimpleMLP)**

```python
class SimpleMLP(nn.Module):
    def __init__(self, input_dim=2000, num_classes=4):
        super().__init__()
        self.network = nn.Sequential(
            # Layer 1: Input â†’ Hidden (2000 â†’ 512)
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.2),

            # Layer 2: Hidden â†’ Hidden (512 â†’ 256)
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.2),

            # Layer 3: Hidden â†’ Hidden (256 â†’ 128)
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.1),  # Reduced dropout before output

            # Layer 4: Hidden â†’ Output (128 â†’ 4)
            nn.Linear(128, num_classes)
        )

        # Kaiming (He) weight initialization for ReLU
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight)
                nn.init.constant_(m.bias, 0)
```

**Detailed Architecture Components:**

| Layer | Type | Input Size | Output Size | Activation | Regularization | Purpose |
|-------|------|------------|-------------|-----------|----------------|---------|
| **Input** | Linear | 2000 | 512 | ReLU | BatchNorm + Dropout(0.2) | Feature compression |
| **Hidden 1** | Linear | 512 | 256 | ReLU | BatchNorm + Dropout(0.2) | Pattern extraction |
| **Hidden 2** | Linear | 256 | 128 | ReLU | BatchNorm + Dropout(0.1) | Feature refinement |
| **Output** | Linear | 128 | 4 | None | None | Class logits |

**Key Design Decisions:**

1. **Progressive Dimensionality Reduction**: 2000 â†’ 512 â†’ 256 â†’ 128 â†’ 4
   - Hierarchical feature learning from k-mer patterns
   - Efficient parameter usage with ~1.19M parameters
   - Prevents overfitting on high-dimensional microbiome data

2. **Regularization Strategy**:
   - **Batch Normalization**: Stabilizes training across federated clients
   - **Dropout**: 0.2 â†’ 0.2 â†’ 0.1 â†’ 0.0 (decreasing pattern)
   - **Kaiming Initialization**: Optimal for ReLU activations

3. **Activation Functions**:
   - **ReLU**: Fast, stable, prevents vanishing gradients
   - **No activation on output**: Raw logits for CrossEntropyLoss

**Network Capacity & Performance:**
- **Total Parameters**: 1,191,044 trainable parameters
- **Memory Footprint**: ~4.6MB model size
- **Inference Speed**: <0.1 seconds on GPU
- **Training Epochs**: 5 per federated round (early convergence)

**Federated Learning Adaptations:**
- **Client Specialization**: Each body site (Mouth, Nasal, Skin, Stool) trains specialized representations
- **Parameter Averaging**: FedAvg aggregates weights across all layers
- **Deterministic Training**: Fixed seeds ensure reproducible federated rounds

### Feature Engineering

**Common Features:**
- **CLR Transformation**: Centered Log-Ratio transformation for compositional data
- **Feature Selection**: SelectKBest with mutual_info_classif (2000 features)
- **Zero Variance Removal**: Eliminates non-informative features

**Centralized Specific:**
- No additional scaling (CLR sufficient for tree-based models)

**Federated Specific:**
- StandardScaler after CLR transformation
- Client-specific data distributions per body site

### Model Training

#### **Centralized Training:**
- **Method**: 5-fold stratified cross-validation
- **Optimization**: Direct XGBoost training
- **Runtime**: ~2.7 minutes for CV + final training
- **Environment**: Local Windows machine 

#### **Federated Training:**
- **Method**: FedAvg with 4 clients (one per body site)
- **Rounds**: Up to 10 rounds (early stopping achieved target performance) 
- **Client Epochs**: 5 epochs per round per client
- **Environment**: Kaggle GPU T4x2

### Validation

#### **Centralized Validation:**
- **Cross-Validation**: 5-fold stratified CV
- **Metrics**: Log Loss, Accuracy, F1-Score
- **Results**:
  - Log Loss: 0.0322 Â± 0.0206
  - Accuracy: 0.9924 Â± 0.0048
  - F1-Score: 0.9920 Â± 0.0050

#### **Federated Validation:**
- **Client Validation**: 15% holdout per client
- **Global Evaluation**: Weighted average across clients
- **Deterministic**: Fixed random seeds ensure reproducible results
- **Results**:
  - Log Loss: 0.0296 Â± 0.0000
  - Accuracy: 0.9962 Â± 0.0000 

### Inference

#### **Centralized Inference:**
- **Input**: Test k-mer matrices
- **Processing**: Same CLR + feature selection pipeline
- **Output**: XGBoost probability predictions

#### **Federated Inference:**
- **Input**: Test k-mer matrices
- **Processing**: CLR + scaling + feature selection
- **Output**: Neural network softmax probabilities

### Deployment
- **Centralized**: Local execution 
- **Federated**: Kaggle kernel deployment with deterministic settings

---

## Runtime & Performance Metrics

### **Centralized Solution (Local Windows)**

| Step | Time | Description |
|------|------|-------------|
| ZIP Extraction | 2.4 minutes | Extract MGB files from archives |
| Training Data Processing | **19.3 hours** | MGBâ†’K-mer via Docker (2901 files) |
| Test Data Processing | **5.7 hours** | MGBâ†’K-mer via Docker (1068 files) |
| Feature Engineering | 7.8 minutes | CLR + feature selection |
| XGBoost Training | 2.7 minutes | 5-fold CV + final model |
| Prediction Generation | 3.2 minutes | Test predictions + submission |
| **ML Training + Inference** | **13.7 minutes** | Pure ML pipeline (feature eng + training + prediction) |
| **Total Pipeline** | **27.0 hours** | Complete end-to-end execution |

### **Federated Solution (Kaggle GPU)**

| Step | Time | Description |
|------|------|-------------|
| Data Preprocessing | 8.5 minutes | CLR + scaling + feature selection |
| Federated Splits | 0.1 seconds | Client data distribution |
| Federated Training | 0.2 minutes | FedAvg training (early stopped) |
| Prediction Generation | 0.1 seconds | Neural network inference |
| **Total Pipeline** | **34.3 minutes** | Complete federated execution |

### **Federated Training Efficiency**
- **Rounds Completed**: 10 (achieved target performance early)
- **GPU Acceleration**: Significant speedup on Kaggle infrastructure
- **Memory Efficiency**: Neural networks handle large feature spaces well

### **Performance Comparison**

| Metric | Centralized | Federated |
|--------|-------------|-----------|
| **Log Loss** | 0.0322  | **0.0296** âœ… |
| **Accuracy** | 0.9924  | **0.9962** âœ… |
| **Training Time** | 27.0 hours | **34.3 minutes** âš¡ |
| **Environment** | Local + Docker | Kaggle GPU |
| **Reproducibility** | âœ… Fixed seeds | âœ… Deterministic |
| **Speed Advantage** | Baseline | **47x faster** ğŸš€ |

---

## LB Score

### **Private Leaderboard Results**
- **Final Rank**: 12th place
- **Centralized Score**: 0.0322 Log Loss
- **Federated Score**: 0.0296 Log Loss (achieved) âœ…


## Error Handling and Logging

### **Centralized Solution**
```python
# Comprehensive error handling
- Batch processing with checkpoints
- Resume capability for interrupted processing
- File existence validation
- Memory management for large k-mer matrices
```

### **Federated Solution**
```python
# Deterministic error handling
- Random seed validation and testing
- Client training failure recovery
- Deterministic algorithm enforcement
```

### **Logging Features**
- **Runtime Tracking**: Detailed timing for each pipeline step
- **Progress Monitoring**: Batch processing progress with estimates
- **Error Logs**: Comprehensive error capture and debugging info

---

## Maintenance and Monitoring

### **Centralized Solution Monitoring**
- K-mer extraction allows experimenting with different k-mer sizes
- Disk space monitoring (large temporary files are cleaned after processing; only two k-mer count files are kept for machine learning)
- Batch processing progress indicators

### **Federated Solution Monitoring**
- Deterministic validation tests
- Client convergence monitoring
- Global model performance tracking
- Communication round efficiency metrics


---

## Environment and Libraries

### **System Requirements**

#### **Centralized Solution (Local)**
- **OS**: Windows 11
- **Docker**: Docker Desktop for Windows
- **Python**: 3.10

#### **Federated Solution (Kaggle)**
- **Environment**: Kaggle GPU Kernels
- **GPU**: Used
- **Python**: 3.8+ (pre-installed)

### **Key Dependencies**

#### **Core Libraries (Both Solutions)**
```
numpy==1.24.3          # Numerical computing
pandas==2.0.3           # Data manipulation
scipy==1.11.1           # Scientific computing
scikit-learn==1.3.0     # Machine learning utilities
```

#### **Centralized Specific**
```
xgboost==1.7.6          # Gradient boosting
Docker Images:
- muefab/genie:latest   # MGB to FASTQ conversion
- jellyfish:2.3.1       # K-mer counting (`quay.io/biocontainers/kmer-jellyfish:2.3.1--py310h184ae93_5`)
```

#### **Federated Specific**
```
torch==2.0.1            # Deep learning framework
torchvision==0.15.2     # Vision utilities (for tensor ops)
```

#### **Development & Monitoring**
```
jupyter==1.0.0          # Notebook environment
```

---

## Files Submitted

### **Primary Notebooks**
1. **`microbiome_solution_notebook.ipynb`** - Centralized XGBoost solution
2. **`federated_microbiome_fixed.ipynb`** - Federated neural network solution

### **Supporting Files**
3. **`requirements.txt`** - Complete dependency list
4. **`README.md`** - Comprehensive documentation (this file)

### **Generated Outputs**
- **`submission_notebook_logloss0.0322.csv`** - Centralized predictions
- **`submission_federated_logloss0.022.csv`** - Federated predictions

### **Data Files (Not Included)**
- `TrainFiles.zip` - Training MGB files
- `TestFiles.zip` - Test MGB files
- `Train.csv` - Metadata and labels
- K-mer matrices (generated by centralized, pre-existing for federated)
- `/kaggle/input/microbiome-challengezindi-kmercount/` - Links to `train_kmercount.csv` and `test_kmercount.csv` resulting from k-mer extraction

---

## ğŸ“Š Results & Visualizations

### Performance Summary

| Solution | Log Loss | Accuracy | F1-Score | Training Time | Environment |
|----------|----------|----------|----------|---------------|-------------|
| **Centralized** | 0.0322 Â± 0.0206 | 99.24% | 99.20% | 27.0 hours | Local + Docker |
| **Federated** | 0.0296 | 99.62% | - | 34.3 minutes | Kaggle GPU |

### Centralized Solution Visualizations

The centralized solution generates 5 comprehensive analysis plots:

1. **microbiome_sample_distribution.png** - Sample distribution by body site
2. **microbiome_kmer_diversity.png** - K-mer abundance patterns
3. **microbiome_dimensionality_reduction.png** - PCA and t-SNE projections
4. **microbiome_model_performance.png** - Confusion matrix and metrics
5. **microbiome_learning_curves.png** - Cross-validation analysis

## ğŸŒ± Carbon Footprint

Complete environmental impact tracking for the centralized solution:

| Component | Duration | COâ‚‚ (g) | Impact Level |
|-----------|----------|---------|--------------|
| **training_data_processing** | 19.3 hours | 75.8 | ğŸ”´ Very High |
| **test_data_processing** | 5.7 hours | 22.5 | ğŸŸ¡ Moderate |
| **Other steps** | ~1 hour | 1.3 | ğŸŸ¢ Low |
| **TOTAL** | **27.02 hours** | **205.8g** | - |

**Environmental Context**: Equivalent to ~0.5 miles of driving or charging a smartphone 25 times.

For detailed carbon analysis, see [`carbon_tracking.md`](carbon_tracking.md).

## ğŸš€ Usage

### Centralized Solution

#### Option 1: Complete Pipeline
```bash
# Run the full notebook
jupyter notebook microbiome_centralized_solution.ipynb
```

#### Option 2: Step-by-Step Execution
```python
# 1. Extract ZIP files
extract_zip_file("TrainFiles.zip", "TrainFiles/")
extract_zip_file("TestFiles.zip", "TestFiles/")

# 2. Process MGB files to k-mers (takes ~25 hours)
process_samples_batch(train_files, "kmer_train/", "train")
process_samples_batch(test_files, "kmer_test/", "test")

# 3. Train XGBoost model
# [Feature engineering + model training + prediction]
```

### Federated Solution

#### Upload to Kaggle
1. Upload `federated_microbiome_fixed.ipynb` to Kaggle
2. Enable GPU runtime
3. Add k-mer dataset: `/kaggle/input/microbiome-challengezindi-kmercount/`
4. Run notebook (~34 minutes total)

### Configuration Options

Modify these parameters for experimentation:

```python
# Centralized Solution
KMER_SIZE = 8              # Try 6, 7, 9, or 10
MIN_KMER_COUNT = 3         # Minimum k-mer frequency
BATCH_SIZE = 10            # Processing batch size
MAX_FEATURES = 2000        # Feature selection limit

# Federated Solution
N_CLIENTS = 4              # Number of federated clients
N_ROUNDS = 10              # Federated rounds
EPOCHS_PER_ROUND = 5       # Client training epochs
```

## ğŸ“ File Structure

```
microbiome-classification/
â”œâ”€â”€ README.md                                    # This documentation
â”œâ”€â”€ requirements.txt                             # Python dependencies
â”œâ”€â”€ carbon_tracking.md                          # Carbon footprint analysis
â”œâ”€â”€ microbiome_centralized_solution.ipynb       # Main centralized notebook
â”œâ”€â”€ microbiome_centralized_solution_backup.ipynb # Backup notebook
â”œâ”€â”€ carbon_tracking/
â”‚   â””â”€â”€ emissions.csv                           # Raw carbon tracking data
â”œâ”€â”€ TrainFiles/                                 # Extracted MGB files (2,901 files)
â”œâ”€â”€ TestFiles/                                  # Extracted MGB files (1,068 files)
â”œâ”€â”€ kmer_train/
â”‚   â”œâ”€â”€ train_kmercount.csv                     # Training k-mer matrix
â”‚   â””â”€â”€ results/                                # Individual processing results
â”œâ”€â”€ kmer_test/
â”‚   â”œâ”€â”€ test_kmercount.csv                      # Test k-mer matrix
â”‚   â””â”€â”€ results/                                # Individual processing results
â”œâ”€â”€ visualizations/                             # Generated analysis plots
â””â”€â”€ submissions/
    â””â”€â”€ submission_notebook_logloss0.0322.csv   # Final predictions
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python code style
- Add docstrings for new functions
- Test Docker integration before submitting
- Monitor carbon footprint for new features
- Update documentation for significant changes

---

## Key Insights

### **Technical Insights**

1. **Streaming Docker Pipeline**:
   - The use of two Docker images to stream the decoding and extraction process was very long (more than 24 hours)
   - This was a good compromise to avoid having 200GB of FASTQ files on the local machine
   - Streaming approach eliminates the need to handle FASTQ files directly

2. **CLR Transformation Critical**:
   - Essential for compositional microbiome data
   - Relative abundance was tried alone and with CLR. Initially, it didn't seem to give good results on the public leaderboard, but later showed excellent performance on the private leaderboard
   - Enables standard ML algorithms on compositional data

3. **Scaling Approach Differences**:
   - **XGBoost**: Tree-based, scale-invariant â†’ CLR only
   - **Neural Networks**: Gradient-based â†’ CLR + StandardScaler

4. **Feature Selection Optimization**:
   - 2000 features optimal for both approaches
   - Mutual information captures non-linear relationships
   - Significant dimensionality reduction (32K+ â†’ 2K features)

5. **Deterministic Training**:
   - Critical for reproducible federated learning
   - Required comprehensive random state control
   - Enabled consistent client ordering and data splits

### **Performance Insights**

1. **Federated > Centralized Performance**:
   - Federated: 0.0296 Log Loss vs Centralized: 0.0322 Log Loss 
   - Federated: 99.62% accuracy vs Centralized: 99.24% 
   - Neural networks better capture complex k-mer patterns
   - Client specialization improves body-site specific predictions

2. **Processing Time Trade-offs**:
   - **Centralized**: 27.0 hours total (25+ hours MGB extraction + 13.7 minutes ML pipeline)
   - **Federated**: 34.3 minutes total (uses pre-processed data)
   - **ML Training Comparison**: 13.7 minutes (centralized) vs 0.3 minutes (federated)
   - **Speed Difference**: 47x faster total pipeline, 46x faster ML training
   - Raw MGBâ†’k-mer extraction is the main bottleneck in centralized


### **Architecture Insights**

1. **Docker Benefits for Centralized**:
   - Reproducible MGB processing environment
   - Complex bioinformatics tool integration
   - Platform-independent execution

2. **Kaggle Advantages for Federated**:
   - Pre-processed data availability
   - GPU acceleration for neural networks
   - Standardized computational environment

3. **Data Distribution Strategy**:
   - Body-site based client assignment logical
   - Each client specializes in specific sample types
   - Cross-client data sharing improves generalization

### **Reproducibility Insights**

1. **Deterministic Requirements**:
   - Multiple random number generators need seeding
   - DataLoader shuffling requires generator seeding
   - Feature selection algorithms need explicit random states

2. **Environment Control**:
   - CUDA deterministic algorithms essential
   - Environment variables for reproducibility
   - Worker initialization in parallel processing

3. **Validation Strategies**:
   - Built-in determinism testing
   - Consistent client ordering critical
   - Round-by-round state verification

---

## Future Improvements

### **Short-term Enhancements**
- [ ] Implement differential privacy for federated clients
- [ ] Add more sophisticated client sampling strategies
- [ ] Optimize Docker processing for faster k-mer extraction
- [ ] Implement ensemble methods combining both approaches

### **Long-term Research Directions**
- [ ] Explore transformer architectures for sequence data
- [ ] Investigate personalized federated learning approaches
- [ ] Develop real-time microbiome classification systems
- [ ] Integrate with clinical decision support systems

---

## Contact & Support

For questions about implementation details or reproduction of results:

- **Technical Issues**: Check logs and error handling sections
- **Docker Problems**: Verify Docker Desktop installation and image availability
- **Kaggle Environment**: Ensure GPU runtime and dataset access
- **Reproducibility**: Verify all random seeds and deterministic settings

---

*Generated with comprehensive analysis of both microbiome classification solutions - Centralized and Federated approaches for MPEG-G challenge.*



